{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %load_ext rpy2.ipython\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr,ttest_ind, ranksums\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import numpy as np\n",
    "import matplotlib, leidenalg, os, pickle\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "from pca import pca\n",
    "import igraph as ig\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, auc\n",
    "from scipy import interp\n",
    "import umap\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "\n",
    "format_fig = 'pdf'\n",
    "\n",
    "def RF_Execute(df,meta, max_iter = 100):\n",
    "    randomstate = 123\n",
    "    X_na = (df).copy()\n",
    "\n",
    "    X=pd.DataFrame()\n",
    "    for i in meta.unique():\n",
    "        tempx=(X_na.reindex(meta[meta==i].index))\n",
    "        X=pd.concat([X,tempx.fillna(tempx.mean())])\n",
    "    X = X.fillna(0)\n",
    "    y=meta.reindex(X.index)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=randomstate)\n",
    "    def RF(it):\n",
    "        clf=RandomForestClassifier(n_estimators = it,bootstrap = True, oob_score = True, random_state = randomstate)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        return [it,metrics.accuracy_score(y_test, y_pred),clf.oob_score_]\n",
    "\n",
    "    select=list(map(RF,range(10,max_iter)))\n",
    "    select = pd.DataFrame(select, columns=['var', 'accuracy', 'oob']).set_index('var')\n",
    "    selected = select.sort_values(['accuracy','oob']).drop_duplicates().index[-1]\n",
    "    clf=RandomForestClassifier(n_estimators = selected,bootstrap = True, oob_score = True, random_state = randomstate)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    thr = 20\n",
    "    feature_imp = pd.Series(clf.feature_importances_,index=X.columns,name = 'Importance').sort_values(ascending=False)\n",
    "    feature_imp = feature_imp[feature_imp>0]\n",
    "    print(\"Accuracy %d: %f | OOB Score: %f\" % (selected,metrics.accuracy_score(y_test, y_pred),clf.oob_score_))\n",
    "    return feature_imp\n",
    "\n",
    "class Network_Analysis:\n",
    "    def __init__(self,raw_data,nodes,respath):\n",
    "        self.res_path=respath\n",
    "        self.writer = pd.ExcelWriter('%s/Supplementary Dataset 16N.xlsx' % self.res_path, engine='xlsxwriter')\n",
    "        self.network_ori=self.__calc(raw_data)\n",
    "        self.nodes=nodes\n",
    "        print('Network Analysis')\n",
    "        self.__net_analysis_combi()\n",
    "        self.writer.save()\n",
    "    \n",
    "    def __calc(self,df):\n",
    "        print('Calculating Correlation..')\n",
    "        temp=spearmanr(df.T)\n",
    "        corr=pd.DataFrame(temp[0],columns=list(df.index),index=list(df.index))\n",
    "        pval=pd.DataFrame(temp[1],columns=list(df.index),index=list(df.index))\n",
    "        print('Filtering the matrix Correlation..')\n",
    "        corr=corr.where(np.triu(np.ones(corr.shape)).astype(np.bool))\n",
    "        pval=pval.where(np.triu(np.ones(pval.shape)).astype(np.bool))\n",
    "        print('Making long table of Correlation..')\n",
    "        corr2=corr.unstack().reset_index(name='weight')\n",
    "        pval2=pval.unstack().reset_index(name='pval')\n",
    "        res=corr2.merge(pval2,on=['level_0','level_1'])\n",
    "        res=res[res['level_0'] != res['level_1']]\n",
    "        res=res.dropna()\n",
    "        res=res[['level_0','level_1','weight','pval']]\n",
    "        res['padj']=multipletests(res['pval'],method='fdr_bh')[1]\n",
    "        res.columns=['source','target','correlation','pvalue','padj']\n",
    "        res=res[res.pvalue < 0.05].reset_index(drop=True)\n",
    "        res.to_excel(self.writer, sheet_name='Edges', index = False)\n",
    "        print('Done!!')\n",
    "        return res\n",
    "    \n",
    "    def __net_analysis_combi(self):\n",
    "        print('Loading The Network...')\n",
    "        temp=self.network_ori\n",
    "        g= ig.Graph.TupleList(zip(temp['source'],temp['target'],temp['correlation']),weights=True)\n",
    "        self.network = g\n",
    "        G_pos = g.subgraph_edges(g.es.select(weight_gt = 0), delete_vertices=False)\n",
    "        G_neg = g.subgraph_edges(g.es.select(weight_lt = 0), delete_vertices=False)\n",
    "        G_neg.es['weight'] = [-w for w in G_neg.es['weight']]\n",
    "        part_pos = leidenalg.ModularityVertexPartition(G_pos, weights='weight')\n",
    "        part_neg = leidenalg.ModularityVertexPartition(G_neg, weights='weight');\n",
    "        optimiser = leidenalg.Optimiser()\n",
    "        diff = optimiser.optimise_partition_multiplex([part_pos, part_neg],layer_weights=[1,-1], n_iterations=-1)\n",
    "        self.clustering_combi=pd.DataFrame(pd.Series(part_pos.membership+part_neg.membership,index=G_pos.vs['name']+G_neg.vs['name'])).reset_index().drop_duplicates().set_index('index')[0]\n",
    "        print('Cluster Analysis...')\n",
    "        self.modularity_combi=diff\n",
    "        self.nodes['cluster'] = self.clustering_combi.reindex(self.nodes.index).tolist()\n",
    "        temp = pd.Series(self.network.degree(),index = self.network.vs['name'],name='Degree').reindex(self.nodes.index)\n",
    "        self.nodes = pd.concat([self.nodes,temp],1)\n",
    "        self.nodes.to_excel(self.writer, sheet_name='Nodes')\n",
    "    \n",
    "    def save_network(self):\n",
    "        print('Saving The Network..')\n",
    "        pickle_out = open('%s/network_object.pkl' % self.res_path,\"wb\")\n",
    "        self.writer = None\n",
    "        pickle.dump(self, pickle_out)\n",
    "        pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical and Physical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "data = temp.iloc[0:,5:]\n",
    "metadata = temp['Liver Fat Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = data.reindex(metadata[metadata == 'Mild'].index)\n",
    "moderate = data.reindex(metadata[metadata == 'Moderate'].index)\n",
    "strong = data.reindex(metadata[metadata == 'Severe'].index)\n",
    "\n",
    "zero = data.reindex(metadata[metadata == 'None'].index)\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in data.columns:\n",
    "    templ = ttest_ind(low[i].dropna(),zero[i].dropna())[1]\n",
    "    tempm = ttest_ind(moderate[i].dropna(),zero[i].dropna())[1]\n",
    "    temps = ttest_ind(strong[i].dropna(),zero[i].dropna())[1]\n",
    "    res.append([i,np.log2(low[i].mean()/zero[i].mean()),np.log2(moderate[i].mean()/zero[i].mean()),np.log2(strong[i].mean()/zero[i].mean()),templ,tempm,temps])\n",
    "\n",
    "res = pd.DataFrame(res,columns=['Measurements','Log2FoldChange (Mild vs None)','Log2FoldChange (Moderate vs None)','Log2FoldChange (Severe vs None)', 'P value (Mild vs None)', 'P value (Moderate vs None)','P value (Severe vs None)']).set_index('Measurements')\n",
    "res.to_excel('../ResultsPaper/DS/Supplementary Dataset 1N_1D.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval=res[res.columns[res.columns.str.contains('P value')]]\n",
    "var=pval[pval<0.05].dropna(how='all').index.tolist()\n",
    "data_1d=data[var[1:]].reindex(metadata.index)\n",
    "data_1d=data_1d.fillna(data_1d.mean())\n",
    "data_1d.index=metadata.tolist()\n",
    "\n",
    "model = pca(n_components=2)\n",
    "results = model.fit_transform(np.log10(data_1d))\n",
    "\n",
    "col_dict=dict(zip(data_1d.index.unique(),sns.color_palette(\"Paired\")))\n",
    "color=(col_dict[i] for i in data_1d.index)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(15,10))\n",
    "sns.scatterplot(ax=ax,data=model.results['PC'].reset_index(),x='PC1',y='PC2',hue='index',s=700,palette=\"tab20\",hue_order=['None','Mild','Moderate','Severe'])\n",
    "ax.set_xlabel('PC1 (%.2f%%)' % (model.results['explained_var'][0]*100))\n",
    "ax.set_ylabel('PC2 (%.2f%%)' % ((model.results['explained_var'][1]-model.results['explained_var'][0])*100))\n",
    "loadings=model.results['loadings']\n",
    "for i in loadings.columns:\n",
    "    temp=loadings[i].tolist()\n",
    "    ax.arrow(0,0,temp[0],temp[1], head_width=0.01, fc='k', ec='k')\n",
    "    ax.text(temp[0],temp[1],i)\n",
    "plt.ylim(ax.get_ylim()[0],1)\n",
    "plt.legend(loc='upper left')\n",
    "# plt.savefig('../ResultsPaper/Figures/1d.'+format_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metagenomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "metadata = temp['Liver Fat Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 3N.xlsx')\n",
    "temp.sheet_names\n",
    "data_gut = temp.parse('Abundance_Gut',index_col=0)\n",
    "data_gut[data_gut <=0] = 10E-4\n",
    "data_gut = data_gut[data_gut.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_gut.columns = [i.split('|')[-1][3:] for i in data_gut.columns]\n",
    "metadata_gut = metadata.reindex(data_gut.index)\n",
    "\n",
    "data_oral = temp.parse('Abundance_Oral',index_col=0)\n",
    "data_oral[data_oral <=0] = 10E-4\n",
    "data_oral = data_oral[data_oral.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_oral.columns = [i.split('|')[-1][3:] for i in data_oral.columns]\n",
    "metadata_oral = metadata.reindex(data_oral.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('../ResultsPaper/DS/Supplementary Dataset 4N.xlsx', engine='xlsxwriter')\n",
    "\n",
    "low = data_gut.reindex(metadata_gut[metadata_gut == 'Mild'].index)\n",
    "moderate = data_gut.reindex(metadata_gut[metadata_gut == 'Moderate'].index)\n",
    "strong = data_gut.reindex(metadata_gut[metadata_gut == 'Severe'].index)\n",
    "zero = data_gut.reindex(metadata_gut[metadata_gut == 'None'].index)\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in data_gut.columns:\n",
    "    templ = ranksums(low[i],zero[i])[1]\n",
    "    tempm = ranksums(moderate[i],zero[i])[1]\n",
    "    temps = ranksums(strong[i],zero[i])[1]\n",
    "    res.append([i,np.log2(low[i].mean()/zero[i].mean()),np.log2(moderate[i].mean()/zero[i].mean()),np.log2(strong[i].mean()/zero[i].mean()),templ,tempm,temps])\n",
    "\n",
    "res = pd.DataFrame(res,columns=['Microbe','Log2FoldChange (Mild vs None)','Log2FoldChange (Moderate vs None)','Log2FoldChange (Severe vs None)','P value (Mild vs None)', 'P value (Moderate vs None)','P value (Severe vs None)']).set_index('Microbe')\n",
    "res.dropna(how = 'all').to_excel(writer, sheet_name='Gut')\n",
    "\n",
    "low = data_oral.reindex(metadata_oral[metadata_oral == 'Mild'].index)\n",
    "moderate = data_oral.reindex(metadata_oral[metadata_oral == 'Moderate'].index)\n",
    "strong = data_oral.reindex(metadata_oral[metadata_oral == 'Severe'].index)\n",
    "zero = data_oral.reindex(metadata_oral[metadata_oral == 'None'].index)\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in data_oral.columns:\n",
    "    templ = ranksums(low[i],zero[i])[1]\n",
    "    tempm = ranksums(moderate[i],zero[i])[1]\n",
    "    temps = ranksums(strong[i],zero[i])[1]\n",
    "    res.append([i,np.log2(low[i].mean()/zero[i].mean()),np.log2(moderate[i].mean()/zero[i].mean()),np.log2(strong[i].mean()/zero[i].mean()),templ,tempm,temps])\n",
    "\n",
    "res = pd.DataFrame(res,columns=['Microbe','Log2FoldChange (Mild vs None)','Log2FoldChange (Moderate vs None)','Log2FoldChange (Severe vs None)','P value (Mild vs None)', 'P value (Moderate vs None)','P value (Severe vs None)']).set_index('Microbe')\n",
    "res.dropna(how = 'all').to_excel(writer, sheet_name='Oral')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['Liver fat (%)',\n",
    " 'Creatinine (mg/dL)',\n",
    " 'Uric acid (mg/dL)',\n",
    " 'ALT (IU/L)',\n",
    " 'AST (IU/L)',\n",
    " 'GGT (U/L)',\n",
    " 'Albumin (g/dL)',\n",
    " 'Creatine Kinase (U/L)',\n",
    " 'Right arm fat free mass (kg/m2)']\n",
    "\n",
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "data_clin = temp.iloc[0:,5:]\n",
    "\n",
    "writer = pd.ExcelWriter('../ResultsPaper/DS/Supplementary Dataset 5N.xlsx', engine='xlsxwriter')\n",
    "\n",
    "\n",
    "res_dict = {}\n",
    "for i in var:\n",
    "    temp_data = pd.concat([data_clin[i],data_gut],1)\n",
    "    x = []\n",
    "    for j in data_gut.columns:\n",
    "        temp = spearmanr(temp_data[i],temp_data[j],nan_policy='omit')\n",
    "        x.append([j,temp[0],temp[1]])\n",
    "    temp = pd.DataFrame(x,columns = ['Metabolites','Correlation','P-Value']).set_index('Metabolites')\n",
    "    res_dict[i] = temp\n",
    "pd.concat(res_dict,axis = 1).to_excel(writer, sheet_name='Gut')\n",
    "\n",
    "res_dict = {}\n",
    "for i in var:\n",
    "    temp_data = pd.concat([data_clin[i],data_oral],1)\n",
    "    x = []\n",
    "    for j in data_oral.columns:\n",
    "        temp = spearmanr(temp_data[i],temp_data[j],nan_policy='omit')\n",
    "        x.append([j,temp[0],temp[1]])\n",
    "    temp = pd.DataFrame(x,columns = ['Metabolites','Correlation','P-Value']).set_index('Metabolites')\n",
    "    res_dict[i] = temp\n",
    "pd.concat(res_dict,axis = 1).to_excel(writer, sheet_name='Oral')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gut and Oral Metagenomics Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 3N.xlsx')\n",
    "\n",
    "data_gut = temp.parse('Abundance_Gut',index_col=0)\n",
    "data_gut[data_gut <= 1] = np.nan\n",
    "data_gut = data_gut[data_gut.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_gut.columns = [i.split('|')[-1][3:] for i in data_gut.columns]\n",
    "metadata_gut = metadata.reindex(data_gut.index)\n",
    "\n",
    "data_oral = temp.parse('Abundance_Oral',index_col=0)\n",
    "data_oral[data_oral <= 1] = np.nan\n",
    "data_oral = data_oral[data_oral.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_oral.columns = [i.split('|')[-1][3:] for i in data_oral.columns]\n",
    "metadata_oral = metadata.reindex(data_oral.index)\n",
    "\n",
    "\n",
    "x = {}\n",
    "for i in data_gut.columns:\n",
    "    t1 = data_gut[i]\n",
    "    y = []\n",
    "    for j in data_oral.columns:\n",
    "        t2 = data_oral.reindex(data_gut.index)[j]\n",
    "        if pd.concat([t1,t2],1).dropna().shape[0] < 5:\n",
    "            continue\n",
    "        temp = spearmanr(t1,t2,nan_policy='omit')\n",
    "        y.append([j,temp[0],temp[1]])\n",
    "    y = pd.DataFrame(y,columns=['Oral','Correlation','P-Value'])\n",
    "    if y.shape[0] == 0:\n",
    "        continue\n",
    "    x[i] = y.set_index('Oral')\n",
    "res = pd.concat(x,axis = 1, keys=x.keys())\n",
    "\n",
    "res.to_excel('../ResultsPaper/DS/Supplementary Dataset 6N.xlsx')\n",
    "\n",
    "corr = pd.DataFrame()\n",
    "pval = pd.DataFrame()\n",
    "\n",
    "for i in res.columns.levels[0]:\n",
    "    temp = res[i]\n",
    "    corr = pd.concat([corr,temp['Correlation']],1).rename(columns = {'Correlation': i})\n",
    "    pval = pd.concat([pval,temp['P-Value']],1).rename(columns = {'P-Value': i})\n",
    "\n",
    "pval[pval > 0.05] = np.nan\n",
    "pval[pval.notna()] = '*'\n",
    "pval = pval.dropna(how='all', axis = 0).dropna(how='all', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_sel = pval.copy().T\n",
    "temp_corr = corr.loc[temp_sel.columns,temp_sel.index].T\n",
    "cmap=matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"#0000a5\",'#0000d8',\"#FFFAF0\",'#d80000',\"#a50000\"])\n",
    "g= sns.clustermap(temp_corr.fillna(0), figsize = (10,7),center = 0, cmap = cmap,xticklabels = 1, yticklabels = 1, annot=temp_sel.fillna(''),annot_kws={\"size\": 15,\"ha\": 'center',\"va\": 'center'},fmt='s', vmin=-1, vmax=1)\n",
    "g.savefig('../ResultsPaper/Figures/Figure 3C.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metabolomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "metadata = temp['Liver Fat Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 7N.xlsx')\n",
    "temp.sheet_names\n",
    "avail = temp.parse('Sample Availability',index_col=0)['Metabolomics']\n",
    "avail = avail[avail == 'YES']\n",
    "data_all = temp.parse('Raw Metabolomics Data',index_col=0)\n",
    "metadata = metadata.reindex(avail.index)\n",
    "data = data_all[avail.index]\n",
    "mapping_pw = data_all.iloc[0:,0:11]\n",
    "\n",
    "#remove metabolites with > 50% NA\n",
    "data = data[(data.isna().sum(1)/data.shape[1]) < 0.5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = data.reindex(metadata[metadata == 'Mild'].index)\n",
    "moderate = data.reindex(metadata[metadata == 'Moderate'].index)\n",
    "strong = data.reindex(metadata[metadata == 'Severe'].index)\n",
    "zero = data.reindex(metadata[metadata == 'None'].index)\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in data.columns:\n",
    "    templ = ttest_ind(low[i].dropna(),zero[i].dropna())[1]\n",
    "    tempm = ttest_ind(moderate[i].dropna(),zero[i].dropna())[1]\n",
    "    temps = ttest_ind(strong[i].dropna(),zero[i].dropna())[1]\n",
    "    res.append([i,np.log2(low[i].mean()/zero[i].mean()),np.log2(moderate[i].mean()/zero[i].mean()),np.log2(strong[i].mean()/zero[i].mean()),templ,tempm,temps])\n",
    "\n",
    "res = pd.DataFrame(res,columns=['Metabolite','Log2FoldChange (Mild vs None)','Log2FoldChange (Moderate vs None)','Log2FoldChange (Severe vs None)','P value (Mild vs None)', 'P value (Moderate vs None)','P value (Severe vs None)']).set_index('Metabolite')\n",
    "res=pd.concat([mapping_pw.reindex(res.index),res],1)\n",
    "res.to_excel('../ResultsPaper/DS/Supplementary Dataset 8N.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['Liver fat (%)',\n",
    " 'Creatinine (mg/dL)',\n",
    " 'Uric acid (mg/dL)',\n",
    " 'ALT (IU/L)',\n",
    " 'AST (IU/L)',\n",
    " 'GGT (U/L)',\n",
    " 'Albumin (g/dL)',\n",
    " 'Creatine Kinase (U/L)',\n",
    " 'Right arm fat free mass (kg/m2)']\n",
    "\n",
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "data_clin = temp.iloc[0:,5:]\n",
    "\n",
    "\n",
    "res_dict = {}\n",
    "for i in var:\n",
    "    temp_data = pd.concat([data_clin[i],data],1)\n",
    "    x = []\n",
    "    for j in data.columns:\n",
    "        temp = spearmanr(temp_data[i],temp_data[j],nan_policy='omit')\n",
    "        x.append([j,temp[0],temp[1]])\n",
    "    temp = pd.DataFrame(x,columns = ['Metabolites','Correlation','P-Value']).set_index('Metabolites')\n",
    "    res_dict[i] = temp\n",
    "pd.concat(res_dict,axis = 1).to_excel('../ResultsPaper/DS/Supplementary Dataset 9N.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proteomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "metadata = temp['Liver Fat Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 10N.xlsx')\n",
    "temp.sheet_names\n",
    "avail = temp.parse('Sample Availability',index_col=0)['Proteomics']\n",
    "avail = avail[avail == 'YES'] \n",
    "data_all = temp.parse('NPX Values',index_col=0)\n",
    "metadata = metadata.reindex(avail.index)\n",
    "data = data_all[avail.index]\n",
    "\n",
    "#remove proteins with > 50% NA\n",
    "data = data[(data.isna().sum(1)/data.shape[1]) < 0.5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = data.reindex(metadata[metadata == 'Mild'].index)\n",
    "moderate = data.reindex(metadata[metadata == 'Moderate'].index)\n",
    "strong = data.reindex(metadata[metadata == 'Severe'].index)\n",
    "zero = data.reindex(metadata[metadata == 'None'].index)\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in data.columns:\n",
    "    templ = ttest_ind(low[i].dropna(),zero[i].dropna())[1]\n",
    "    tempm = ttest_ind(moderate[i].dropna(),zero[i].dropna())[1]\n",
    "    temps = ttest_ind(strong[i].dropna(),zero[i].dropna())[1]\n",
    "    res.append([i,np.log2(low[i].mean()/zero[i].mean()),np.log2(moderate[i].mean()/zero[i].mean()),np.log2(strong[i].mean()/zero[i].mean()),templ,tempm,temps])\n",
    "\n",
    "res = pd.DataFrame(res,columns=['Protein','Log2FoldChange (Mild vs None)','Log2FoldChange (Moderate vs None)','Log2FoldChange (Severe vs None)','P value (Mild vs None)', 'P value (Moderate vs None)','P value (Severe vs None)']).set_index('Protein')\n",
    "res.to_excel('../ResultsPaper/DS/Supplementary Dataset 11N.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['Liver fat (%)',\n",
    " 'Creatinine (mg/dL)',\n",
    " 'Uric acid (mg/dL)',\n",
    " 'ALT (IU/L)',\n",
    " 'AST (IU/L)',\n",
    " 'GGT (U/L)',\n",
    " 'Albumin (g/dL)',\n",
    " 'Creatine Kinase (U/L)',\n",
    " 'Right arm fat free mass (kg/m2)']\n",
    "\n",
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "data_clin = temp.iloc[0:,5:]\n",
    "\n",
    "res_dict = {}\n",
    "for i in var:\n",
    "    temp_data = pd.concat([data_clin[i],data],1)\n",
    "    x = []\n",
    "    for j in data.columns:\n",
    "        temp = spearmanr(temp_data[i],temp_data[j],nan_policy='omit')\n",
    "        x.append([j,temp[0],temp[1]])\n",
    "    temp = pd.DataFrame(x,columns = ['Metabolites','Correlation','P-Value']).set_index('Metabolites')\n",
    "    temp['FDR']=multipletests(temp['P-Value'],method='fdr_bh')[1]\n",
    "    res_dict[i] = temp\n",
    "pd.concat(res_dict,axis = 1).to_excel('../ResultsPaper/DS/Supplementary Dataset 12N.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "metadata = temp['Liver Fat Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 3N.xlsx')\n",
    "temp.sheet_names\n",
    "data_gut = temp.parse('Abundance_Gut',index_col=0)\n",
    "data_gut = data_gut[data_gut.index.str.contains('\\|c__') & ~data_gut.index.str.contains('\\|f__') & ~data_gut.index.str.contains('\\|o__')].dropna(how = 'all').T\n",
    "data_gut.columns = [i.split('|')[-1][3:] for i in data_gut.columns]\n",
    "metadata_gut = metadata.reindex(data_gut.index)\n",
    "\n",
    "data_oral = temp.parse('Abundance_Oral',index_col=0)\n",
    "data_oral = data_oral[data_oral.index.str.contains('\\|c__') & ~data_oral.index.str.contains('\\|f__') & ~data_oral.index.str.contains('\\|o__')].dropna(how = 'all').T\n",
    "data_oral.columns = [i.split('|')[-1][3:] for i in data_oral.columns]\n",
    "metadata_oral = metadata.reindex(data_oral.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([data_gut,metadata_gut],1).groupby('Liver Fat Class').mean()\n",
    "temp = (temp.T*100/temp.sum(1))\n",
    "temp = temp[temp>1].dropna(how='all')[['None','Mild', 'Moderate', 'Severe']]\n",
    "temp.loc['Others'] = 100 - temp.sum()\n",
    "temp = temp.sort_values(['None','Mild', 'Moderate', 'Severe'][::-1], ascending = False)\n",
    "temp.T.plot(kind='bar', stacked=True,cmap = 'tab20')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Abundance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../ResultsPaper/Figures/Figure 2C.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([data_oral,metadata_oral],1).groupby('Liver Fat Class').mean()\n",
    "temp = (temp.T*100/temp.sum(1))\n",
    "temp = temp[temp>1].dropna(how='all')[['None','Mild', 'Moderate', 'Severe']]\n",
    "temp.loc['Others'] = 100 - temp.sum()\n",
    "temp = temp.sort_values(['None','Mild', 'Moderate', 'Severe'][::-1], ascending = False)\n",
    "temp.T.plot(kind='bar', stacked=True,cmap = 'tab20')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Abundance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../ResultsPaper/Figures/Figure 2D.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gut and Oral vs Proteomics and Metabolomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "metadata = temp['Liver Fat Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 3N.xlsx')\n",
    "\n",
    "data_gut = temp.parse('Abundance_Gut',index_col=0)\n",
    "data_gut[data_gut <= 1] = np.nan\n",
    "data_gut = data_gut[data_gut.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_gut.columns = [i.split('|')[-1][3:] for i in data_gut.columns]\n",
    "metadata_gut = metadata.reindex(data_gut.index)\n",
    "\n",
    "data_oral = temp.parse('Abundance_Oral',index_col=0)\n",
    "data_oral[data_oral <= 1] = np.nan\n",
    "data_oral = data_oral[data_oral.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_oral.columns = [i.split('|')[-1][3:] for i in data_oral.columns]\n",
    "metadata_oral = metadata.reindex(data_oral.index)\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 10N.xlsx')\n",
    "temp.sheet_names\n",
    "avail = temp.parse('Sample Availability',index_col=0)['Proteomics']\n",
    "avail = avail[avail == 'YES'] \n",
    "data_all = temp.parse('NPX Values',index_col=0)\n",
    "metadata = metadata.reindex(avail.index)\n",
    "data = data_all[avail.index]\n",
    "\n",
    "#remove proteins with > 50% NA\n",
    "data_prot = data[(data.isna().sum(1)/data.shape[1]) < 0.5].T\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 7N.xlsx')\n",
    "temp.sheet_names\n",
    "avail = temp.parse('Sample Availability',index_col=0)['Metabolomics']\n",
    "avail = avail[avail == 'YES']\n",
    "data_all = temp.parse('Raw Metabolomics Data',index_col=0)\n",
    "metadata = metadata.reindex(avail.index)\n",
    "data = data_all[avail.index]\n",
    "mapping_pw = data_all.iloc[0:,0:11]\n",
    "\n",
    "#remove metabolites with > 50% NA\n",
    "data_met = data[(data.isna().sum(1)/data.shape[1]) < 0.5].T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {}\n",
    "for i in data_gut.columns:\n",
    "    t1 = data_gut[i]\n",
    "    y = []\n",
    "    for j in data_met.columns:\n",
    "        t2 = data_met.reindex(data_gut.index)[j]\n",
    "        if pd.concat([t1,t2],1).dropna().shape[0] < 5:\n",
    "            continue\n",
    "        temp = spearmanr(t1,t2,nan_policy='omit')\n",
    "        y.append([j,temp[0],temp[1]])\n",
    "    y = pd.DataFrame(y,columns=['Metabolites','Correlation','P-Value'])\n",
    "    if y.shape[0] == 0:\n",
    "        continue\n",
    "    x[i] = y.set_index('Metabolites')\n",
    "res_gut = pd.concat(x,axis = 1, keys=x.keys())\n",
    "\n",
    "x = {}\n",
    "for i in data_oral.columns:\n",
    "    t1 = data_oral[i]\n",
    "    y = []\n",
    "    for j in data_met.columns:\n",
    "        t2 = data_met.reindex(data_oral.index)[j]\n",
    "        if pd.concat([t1,t2],1).dropna().shape[0] < 5:\n",
    "            continue\n",
    "        temp = spearmanr(t1,t2,nan_policy='omit')\n",
    "        y.append([j,temp[0],temp[1]])\n",
    "    y = pd.DataFrame(y,columns=['Metabolites','Correlation','P-Value'])\n",
    "    if y.shape[0] == 0:\n",
    "        continue\n",
    "    x[i] = y.set_index('Metabolites')\n",
    "res_oral = pd.concat(x,axis = 1, keys=x.keys())\n",
    "\n",
    "writer = pd.ExcelWriter('../ResultsPaper/DS/Supplementary Dataset 13N.xlsx')\n",
    "res_gut.to_excel(writer, sheet_name = 'Gut')\n",
    "res_oral.to_excel(writer, sheet_name = 'Oral')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 13N.xlsx')\n",
    "res_oral = temp.parse('Oral',index_col = 0, header = [0,1])\n",
    "res_gut = temp.parse('Gut',index_col = 0, header = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res_oral.copy()\n",
    "corr = pd.DataFrame()\n",
    "pval = pd.DataFrame()\n",
    "\n",
    "for i in res.columns.levels[0]:\n",
    "    temp = res[i]\n",
    "    corr = pd.concat([corr,temp['Correlation']],1).rename(columns = {'Correlation': i})\n",
    "    pval = pd.concat([pval,temp['P-Value']],1).rename(columns = {'P-Value': i})\n",
    "pval[pval > 0.05] = np.nan\n",
    "pval[pval.notna()] = '*'\n",
    "pval = pval.dropna(how='all', axis = 0).dropna(how='all', axis = 1)\n",
    "\n",
    "temp_sel = pval.copy().T\n",
    "temp_sel = temp_sel.T[temp_sel.notna().sum() >= 5].T.dropna(how = 'all')\n",
    "temp_corr = corr.loc[temp_sel.columns,temp_sel.index].T\n",
    "\n",
    "cmap=matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"#0000a5\",'#0000d8',\"#FFFAF0\",'#d80000',\"#a50000\"])\n",
    "g= sns.clustermap(temp_corr.fillna(0), figsize = (20,15),center = 0, cmap = cmap,xticklabels = 1, yticklabels = 1, annot=temp_sel.fillna(''),annot_kws={\"size\": 15,\"ha\": 'center',\"va\": 'center'},fmt='s', vmin=-1, vmax=1)\n",
    "g.savefig('../ResultsPaper/Figures/Figure S2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res_gut.copy()\n",
    "corr = pd.DataFrame()\n",
    "pval = pd.DataFrame()\n",
    "\n",
    "for i in res.columns.levels[0]:\n",
    "    temp = res[i]\n",
    "    corr = pd.concat([corr,temp['Correlation']],1).rename(columns = {'Correlation': i})\n",
    "    pval = pd.concat([pval,temp['P-Value']],1).rename(columns = {'P-Value': i})\n",
    "\n",
    "pval[pval > 0.05] = np.nan\n",
    "pval[pval.notna()] = '*'\n",
    "pval = pval.dropna(how='all', axis = 0).dropna(how='all', axis = 1)\n",
    "temp_sel = pval.copy().T\n",
    "temp_sel = temp_sel.T[temp_sel.notna().sum() >= 5].T.dropna(how = 'all')\n",
    "temp_corr = corr.loc[temp_sel.columns,temp_sel.index].T\n",
    "\n",
    "cmap=matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"#0000a5\",'#0000d8',\"#FFFAF0\",'#d80000',\"#a50000\"])\n",
    "g= sns.clustermap(temp_corr.fillna(0), figsize = (10,10),center = 0, cmap = cmap,xticklabels = 1, yticklabels = 1, annot=temp_sel.fillna(''),annot_kws={\"size\": 15,\"ha\": 'center',\"va\": 'center'},fmt='s', vmin=-1, vmax=1)\n",
    "g.savefig('../ResultsPaper/Figures/Figure S3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {}\n",
    "for i in data_gut.columns:\n",
    "    t1 = data_gut[i]\n",
    "    y = []\n",
    "    for j in data_prot.columns:\n",
    "        t2 = data_prot.reindex(data_gut.index)[j]\n",
    "        if pd.concat([t1,t2],1).dropna().shape[0] < 5:\n",
    "            continue\n",
    "        temp = spearmanr(t1,t2,nan_policy='omit')\n",
    "        y.append([j,temp[0],temp[1]])\n",
    "    y = pd.DataFrame(y,columns=['Proteins','Correlation','P-Value'])\n",
    "    if y.shape[0] == 0:\n",
    "        continue\n",
    "    x[i] = y.set_index('Proteins')\n",
    "res_gut = pd.concat(x,axis = 1, keys=x.keys())\n",
    "\n",
    "x = {}\n",
    "for i in data_oral.columns:\n",
    "    t1 = data_oral[i]\n",
    "    y = []\n",
    "    for j in data_prot.columns:\n",
    "        t2 = data_prot.reindex(data_oral.index)[j]\n",
    "        if pd.concat([t1,t2],1).dropna().shape[0] < 5:\n",
    "            continue\n",
    "        temp = spearmanr(t1,t2,nan_policy='omit')\n",
    "        y.append([j,temp[0],temp[1]])\n",
    "    y = pd.DataFrame(y,columns=['Proteins','Correlation','P-Value'])\n",
    "    if y.shape[0] == 0:\n",
    "        continue\n",
    "    x[i] = y.set_index('Proteins')\n",
    "res_oral = pd.concat(x,axis = 1, keys=x.keys())\n",
    "\n",
    "writer = pd.ExcelWriter('../ResultsPaper/DS/Supplementary Dataset 14N.xlsx')\n",
    "res_gut.to_excel(writer, sheet_name = 'Gut')\n",
    "res_oral.to_excel(writer, sheet_name = 'Oral')\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 14N.xlsx')\n",
    "res_oral = temp.parse('Oral',index_col = 0, header = [0,1])\n",
    "res_gut = temp.parse('Gut',index_col = 0, header = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res_oral.copy()\n",
    "corr = pd.DataFrame()\n",
    "pval = pd.DataFrame()\n",
    "\n",
    "for i in res.columns.levels[0]:\n",
    "    temp = res[i]\n",
    "    corr = pd.concat([corr,temp['Correlation']],1).rename(columns = {'Correlation': i})\n",
    "    pval = pd.concat([pval,temp['P-Value']],1).rename(columns = {'P-Value': i})\n",
    "pval[pval > 0.05] = np.nan\n",
    "pval[pval.notna()] = '*'\n",
    "pval = pval.dropna(how='all', axis = 0).dropna(how='all', axis = 1)\n",
    "temp_sel = pval.copy().T\n",
    "temp_corr = corr.loc[temp_sel.columns,temp_sel.index].T\n",
    "\n",
    "cmap=matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"#0000a5\",'#0000d8',\"#FFFAF0\",'#d80000',\"#a50000\"])\n",
    "g= sns.clustermap(temp_corr.fillna(0), figsize = (15,10),center = 0, cmap = cmap,xticklabels = 1, yticklabels = 1, annot=temp_sel.fillna(''),annot_kws={\"size\": 15,\"ha\": 'center',\"va\": 'center'},fmt='s', vmin=-1, vmax=1)\n",
    "g.savefig('../ResultsPaper/Figures/Figure S4.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res_gut.copy()\n",
    "corr = pd.DataFrame()\n",
    "pval = pd.DataFrame()\n",
    "\n",
    "for i in res.columns.levels[0]:\n",
    "    temp = res[i]\n",
    "    corr = pd.concat([corr,temp['Correlation']],1).rename(columns = {'Correlation': i})\n",
    "    pval = pd.concat([pval,temp['P-Value']],1).rename(columns = {'P-Value': i})\n",
    "pval[pval > 0.05] = np.nan\n",
    "pval[pval.notna()] = '*'\n",
    "pval = pval.dropna(how='all', axis = 0).dropna(how='all', axis = 1)\n",
    "temp_sel = pval.copy().T\n",
    "temp_corr = corr.loc[temp_sel.columns,temp_sel.index].T\n",
    "\n",
    "cmap=matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"#0000a5\",'#0000d8',\"#FFFAF0\",'#d80000',\"#a50000\"])\n",
    "g= sns.clustermap(temp_corr.fillna(0), figsize = (15,7),center = 0, cmap = cmap,xticklabels = 1, yticklabels = 1, annot=temp_sel.fillna(''),annot_kws={\"size\": 15,\"ha\": 'center',\"va\": 'center'},fmt='s', vmin=-1, vmax=1)\n",
    "g.savefig('../ResultsPaper/Figures/Figure S5.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Biomarkers Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "data_clin = temp.iloc[0:,5:]\n",
    "metadata = temp['Liver Fat Class']\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 7N.xlsx')\n",
    "temp.sheet_names\n",
    "avail = temp.parse('Sample Availability',index_col=0)['Metabolomics']\n",
    "avail = avail[avail == 'YES']\n",
    "data_all = temp.parse('Raw Metabolomics Data',index_col=0)\n",
    "metadata = metadata.reindex(avail.index)\n",
    "data = data_all[avail.index]\n",
    "mapping_pw = data_all.iloc[0:,0:11]\n",
    "\n",
    "#remove metabolites with > 50% NA\n",
    "data_met = data[(data.isna().sum(1)/data.shape[1]) < 0.5].T\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 10N.xlsx')\n",
    "temp.sheet_names\n",
    "avail = temp.parse('Sample Availability',index_col=0)['Proteomics']\n",
    "avail = avail[avail == 'YES'] \n",
    "data_all = temp.parse('NPX Values',index_col=0)\n",
    "metadata = metadata.reindex(avail.index)\n",
    "data = data_all[avail.index]\n",
    "\n",
    "#remove proteins with > 50% NA\n",
    "data_prot = data[(data.isna().sum(1)/data.shape[1]) < 0.5].T\n",
    "\n",
    "samples_intersect = set(data_prot.index).intersection(set(data_met.index)).intersection(set(data_clin.index))\n",
    "data = pd.concat([data_clin.reindex(samples_intersect), data_met.reindex(samples_intersect), data_prot.reindex(samples_intersect)],1)\n",
    "del data['Liver fat (%)']\n",
    "\n",
    "\n",
    "metadata = metadata.reindex(samples_intersect)\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 3N.xlsx')\n",
    "temp.sheet_names\n",
    "data_gut = temp.parse('Abundance_Gut',index_col=0)\n",
    "data_gut = data_gut[data_gut.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_gut.columns = [i.split('|')[-1][3:]+' (GUT)' for i in data_gut.columns]\n",
    "\n",
    "data_oral = temp.parse('Abundance_Oral',index_col=0)\n",
    "data_oral = data_oral[data_oral.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_oral.columns = [i.split('|')[-1][3:]+' (ORAL)' for i in data_oral.columns]\n",
    "\n",
    "samples_intersect = set(data_oral.index).intersection(set(data_gut.index))\n",
    "data_microb = pd.concat([data_oral.reindex(samples_intersect),data_gut.reindex(samples_intersect)],1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_clin = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N_1D.xlsx',index_col=0)\n",
    "stats_clin = stats_clin[stats_clin.columns[stats_clin.columns.str.contains(' vs ')]]\n",
    "stats_clin['Location'] = 'CLINICAL'\n",
    "\n",
    "stats_met = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 8N.xlsx',index_col=0)\n",
    "stats_met = stats_met[stats_met.columns[stats_met.columns.str.contains(' vs ')]]#.iloc[0:,0:-3]\n",
    "stats_met['Location'] = 'METABOLITE'\n",
    "\n",
    "stats_prot = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 11N.xlsx',index_col=0)\n",
    "stats_prot = stats_prot[stats_prot.columns[stats_prot.columns.str.contains(' vs ')]]\n",
    "stats_prot['Location'] = 'PROTEIN'\n",
    "\n",
    "\n",
    "stats_gut = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 4N.xlsx',index_col=0, sheet_name='Gut')\n",
    "stats_gut = stats_gut[stats_gut.columns[stats_gut.columns.str.contains(' vs ')]]\n",
    "stats_gut.index = stats_gut.index + ' (GUT)'\n",
    "stats_gut['Location'] = 'GUT'\n",
    "\n",
    "\n",
    "stats_oral = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 4N.xlsx',index_col=0, sheet_name='Oral')\n",
    "stats_oral = stats_oral[stats_oral.columns[stats_oral.columns.str.contains(' vs ')]]\n",
    "stats_oral.index = stats_oral.index + ' (ORAL)'\n",
    "stats_oral['Location'] = 'ORAL'\n",
    "\n",
    "stats_all = pd.concat([stats_clin, stats_met, stats_prot,stats_oral,stats_gut])\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 7N.xlsx')\n",
    "mapping_pw = temp.parse('Raw Metabolomics Data',index_col=0).iloc[0:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomstate = 123\n",
    "\n",
    "writer = pd.ExcelWriter('../ResultsPaper/DS/Supplementary Dataset 15N.xlsx', engine='xlsxwriter')\n",
    "\n",
    "print('Clinical (C) (ALL):')\n",
    "RF_clin = RF_Execute(data_clin.iloc[0:,1:],metadata)\n",
    "RF_clin=pd.concat([RF_clin,stats_clin.reindex(RF_clin.index)],1)\n",
    "RF_clin.to_excel(writer, sheet_name='Clinical')\n",
    "\n",
    "print('Metabolomics (M) (ALL):')\n",
    "RF_met = RF_Execute(data_met,metadata)\n",
    "RF_met=pd.concat([RF_met,mapping_pw.reindex(RF_met.index),stats_met.reindex(RF_met.index)],1)\n",
    "RF_met.to_excel(writer, sheet_name='Metabolites')\n",
    "\n",
    "print('Proteomics (P) (ALL):')\n",
    "RF_prot = RF_Execute(data_prot,metadata)\n",
    "RF_prot=pd.concat([RF_prot,stats_prot.reindex(RF_prot.index)],1)\n",
    "RF_prot.to_excel(writer, sheet_name='Proteins')\n",
    "\n",
    "print('Gut (G) (ALL):')\n",
    "RF_gut = RF_Execute(data_gut,metadata)\n",
    "RF_gut=pd.concat([RF_gut,stats_gut.reindex(RF_gut.index)],1)\n",
    "RF_gut.to_excel(writer, sheet_name='Gut')\n",
    "\n",
    "print('Oral (O) (ALL):')\n",
    "RF_oral = RF_Execute(data_oral,metadata)\n",
    "RF_oral=pd.concat([RF_oral,stats_oral.reindex(RF_oral.index)],1)\n",
    "RF_oral.to_excel(writer, sheet_name='Oral')\n",
    "\n",
    "var = RF_clin.iloc[0:5].index.tolist()\n",
    "print('C(5):')\n",
    "RF = RF_Execute(data[var],metadata)\n",
    "RF = pd.concat([RF,pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C(5)')\n",
    "\n",
    "var = RF_clin.iloc[0:10].index.tolist()\n",
    "print('C(10):')\n",
    "RF = RF_Execute(data[var],metadata)\n",
    "RF = pd.concat([RF,pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C(10)')\n",
    "\n",
    "var = RF_met.iloc[0:5].index.tolist()\n",
    "print('M(5):')\n",
    "RF = RF_Execute(data[var],metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='M(5)')\n",
    "\n",
    "var = RF_met.iloc[0:10].index.tolist()\n",
    "print('M(10):')\n",
    "RF = RF_Execute(data[var],metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='M(10)')\n",
    "\n",
    "var = RF_prot.iloc[0:5].index.tolist()\n",
    "print('P(5):')\n",
    "RF = RF_Execute(data[var],metadata)\n",
    "RF = pd.concat([RF,pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='P(5)')\n",
    "\n",
    "var = RF_prot.iloc[0:10].index.tolist()\n",
    "print('P(10):')\n",
    "RF = RF_Execute(data[var],metadata)\n",
    "RF = pd.concat([RF,pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='P(10)')\n",
    "\n",
    "var = RF_gut[0:5].index.tolist()\n",
    "print('G(5):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='G(5)')\n",
    "\n",
    "var = RF_gut[0:10].index.tolist()\n",
    "print('G(10):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='G(10)')\n",
    "\n",
    "var = RF_oral[0:5].index.tolist()\n",
    "print('O(5):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='O(5)')\n",
    "\n",
    "\n",
    "var = RF_oral[0:10].index.tolist()\n",
    "print('O(10):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='O(10)')\n",
    "\n",
    "print('C + M + P + G + O (ALL):')\n",
    "RF = RF_Execute(pd.concat([data,data_oral.dropna(how='all',axis = 1).fillna(0),data_gut.dropna(how='all',axis = 1).fillna(0)],1),metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C + M + P + G + O (ALL)')\n",
    "\n",
    "var = RF_clin.iloc[0:5].index.tolist()+RF_met.iloc[0:10].index.tolist()+RF_prot.iloc[0:5].index.tolist()\n",
    "print('C(5) + M(10) + P(5):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C(5) + M(10) + P(5)')\n",
    "\n",
    "var = RF_clin.iloc[0:5].index.tolist()+RF_met.iloc[0:10].index.tolist()+RF_prot.iloc[0:5].index.tolist()+RF_gut[0:10].index.tolist()\n",
    "print('C(5) + M(10) + P(5) + G(10):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C(5) + M(10) + P(5) + G(10)')\n",
    "\n",
    "var = RF_clin.iloc[0:5].index.tolist()+RF_met.iloc[0:10].index.tolist()+RF_prot.iloc[0:5].index.tolist()+RF_oral[0:10].index.tolist()\n",
    "print('C(5) + M(10) + P(5) + O(10):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C(5) + M(10) + P(5) + O(10)')\n",
    "\n",
    "var = RF_clin.iloc[0:5].index.tolist()+RF_met.iloc[0:10].index.tolist()+RF_prot.iloc[0:5].index.tolist()+RF_gut[0:10].index.tolist()+RF_oral[0:10].index.tolist()\n",
    "print('C(5) + M(10) + P(5) + G(10) + O(10):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C(5)+M(10)+P(5)+G(10)+O(10)')\n",
    "\n",
    "var = RF_clin.iloc[0:5].index.tolist()+RF_met.iloc[0:5].index.tolist()+RF_prot.iloc[0:5].index.tolist()\n",
    "print('C(5) + M(5) + P(5):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C(5) + M(5) + P(5)')\n",
    "\n",
    "var = RF_clin.iloc[0:5].index.tolist()+RF_met.iloc[0:5].index.tolist()+RF_prot.iloc[0:5].index.tolist()+RF_gut[0:5].index.tolist()\n",
    "print('C(5) + M(5) + P(5) + G(5):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C(5) + M(5) + P(5)')\n",
    "\n",
    "var = RF_clin.iloc[0:5].index.tolist()+RF_met.iloc[0:5].index.tolist()+RF_prot.iloc[0:5].index.tolist()+RF_oral[0:5].index.tolist()\n",
    "print('C(5) + M(5) + P(5) + O(5):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C(5) + M(5) + P(5) + O(5)')\n",
    "\n",
    "var = RF_clin.iloc[0:5].index.tolist()+RF_met.iloc[0:5].index.tolist()+RF_prot.iloc[0:5].index.tolist()+RF_gut[0:5].index.tolist()+RF_oral[0:5].index.tolist()\n",
    "print('C(5) + M(5) + P(5) + G(5) + O(5):')\n",
    "RF = RF_Execute(pd.concat([data,data_microb],1)[var],metadata)\n",
    "RF = pd.concat([RF,mapping_pw.reindex(RF.index),pd.concat([stats_all,],1).reindex(RF.index)],1)\n",
    "RF.to_excel(writer, sheet_name='C(5)+M(5)+P(5)+G(5)+O(5)')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "data_clin = temp.iloc[0:,5:]\n",
    "metadata = temp['Liver Fat Class']\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 7N.xlsx')\n",
    "temp.sheet_names\n",
    "avail = temp.parse('Sample Availability',index_col=0)['Metabolomics']\n",
    "avail = avail[avail == 'YES']\n",
    "data_all = temp.parse('Raw Metabolomics Data',index_col=0)\n",
    "metadata = metadata.reindex(avail.index)\n",
    "data = data_all[avail.index]\n",
    "mapping_pw = data_all.iloc[0:,0:11]\n",
    "\n",
    "#remove metabolites with > 50% NA\n",
    "data_met = data[(data.isna().sum(1)/data.shape[1]) < 0.5].T\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 10N.xlsx')\n",
    "temp.sheet_names\n",
    "avail = temp.parse('Sample Availability',index_col=0)['Proteomics']\n",
    "avail = avail[avail == 'YES'] \n",
    "data_all = temp.parse('NPX Values',index_col=0)\n",
    "metadata = metadata.reindex(avail.index)\n",
    "data = data_all[avail.index]\n",
    "\n",
    "#remove proteins with > 50% NA\n",
    "data_prot = data[(data.isna().sum(1)/data.shape[1]) < 0.5].T\n",
    "\n",
    "samples_intersect = set(data_prot.index).intersection(set(data_met.index)).intersection(set(data_clin.index))\n",
    "data = pd.concat([data_clin.reindex(samples_intersect), data_met.reindex(samples_intersect), data_prot.reindex(samples_intersect)],1)\n",
    "del data['Liver fat (%)']\n",
    "\n",
    "\n",
    "metadata = metadata.reindex(samples_intersect)\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 3N.xlsx')\n",
    "temp.sheet_names\n",
    "data_gut = temp.parse('Abundance_Gut',index_col=0)\n",
    "data_gut = data_gut[data_gut.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_gut.columns = [i.split('|')[-1][3:]+' (GUT)' for i in data_gut.columns]\n",
    "\n",
    "data_oral = temp.parse('Abundance_Oral',index_col=0)\n",
    "data_oral = data_oral[data_oral.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_oral.columns = [i.split('|')[-1][3:]+' (ORAL)' for i in data_oral.columns]\n",
    "\n",
    "samples_intersect = set(data_oral.index).intersection(set(data_gut.index))\n",
    "data_microb = pd.concat([data_oral.reindex(samples_intersect),data_gut.reindex(samples_intersect)],1).fillna(0)\n",
    "\n",
    "## Validation\n",
    "\n",
    "temp = pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 2N.xlsx')\n",
    "sheets = ['Dataset 2A','Dataset 2E-Oral','Dataset 2F-Gut','Dataset 2G-Metabolomics','Dataset 2H-Proteomics']\n",
    "v4 = pd.DataFrame()\n",
    "for i in sheets:\n",
    "    v4 = pd.concat([v4,temp.parse(i,index_col = 0)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = '''ALT (IU/L)\n",
    "Uric acid (mg/dL)\n",
    "Insulin (mg/dL)\n",
    "AST (IU/L)\n",
    "Left leg fat mass (kg/m2)\n",
    "High Density Lipoprotein (mg/dL)\n",
    "Trunk total body water (%)\n",
    "GGT (U/L)\n",
    "Glucose (mg/dL)\n",
    "Left arm fat free mass (kg/m2)'''.split('\\n')\n",
    "\n",
    "M = '''5-(galactosylhydroxy)-L-lysine\n",
    "N-acetyl-1-methylhistidine*\n",
    "phenol glucuronide\n",
    "N,N-dimethyl-5-aminovalerate\n",
    "N-methyltaurine\n",
    "diacylglycerol (14:0/18:1, 16:0/16:1) [2]*\n",
    "vanillic acid glycine\n",
    "N,N-dimethylalanine\n",
    "3-hydroxy-2-methylpyridine sulfate\n",
    "3-(3-hydroxyphenyl)propionate sulfate'''.split('\\n')\n",
    "\n",
    "P = '''CDCP1\n",
    "FGF-21\n",
    "CXCL6\n",
    "CXCL9\n",
    "LAP TGF-beta-1\n",
    "CD244\n",
    "ST1A1\n",
    "LIF-R\n",
    "Flt3L\n",
    "SIRT2'''.split('\\n')\n",
    "\n",
    "G = '''Dorea_longicatena (GUT)\n",
    "Barnesiella_intestinihominis (GUT)\n",
    "Coprococcus_comes (GUT)\n",
    "Roseburia_intestinalis (GUT)\n",
    "Rothia_mucilaginosa (GUT)\n",
    "Allisonella_histaminiformans (GUT)\n",
    "Ruminococcus_bromii (GUT)\n",
    "Prevotella_sp_CAG_279 (GUT)\n",
    "Flavonifractor_plautii (GUT)\n",
    "Butyricimonas_virosa (GUT)'''.split('\\n')\n",
    "\n",
    "O = '''Veillonella_infantium (ORAL)\n",
    "Actinomyces_naeslundii (ORAL)\n",
    "Porphyromonas_somerae (ORAL)\n",
    "Solobacterium_moorei (ORAL)\n",
    "Campylobacter_concisus (ORAL)\n",
    "Neisseria_flavescens (ORAL)\n",
    "Prevotella_nigrescens (ORAL)\n",
    "Abiotrophia_sp_HMSC24B09 (ORAL)\n",
    "Bacteroides_uniformis (ORAL)\n",
    "Kingella_oralis (ORAL)'''.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {\n",
    "    'C(ALL)' : data_clin.columns[1:],\n",
    "    'M(ALL)' : data_met.columns,\n",
    "    'P(ALL)' : data_prot.columns,\n",
    "    'O(ALL)' : data_oral.columns,\n",
    "    'G(ALL)' : data_gut.columns,\n",
    "    'C(5)': C[0:5], \n",
    "    'C(10)': C,\n",
    "    'M(5)': M[0:5],\n",
    "    'M(10)': M,\n",
    "    'P(5)': P[0:5], \n",
    "    'P(10)': P,\n",
    "    'G(5)': G[0:5],\n",
    "    'G(10)': G, \n",
    "    'O(5)': O[0:5],\n",
    "    'O(10)': O,\n",
    "    'C(5) + M(10) + P(5))': C[0:5] + M +P[0:5],\n",
    "    'C(5) + M(10) + P(5) + G(10)': C[0:5] + M +P[0:5] + G,\n",
    "    'C(5) + M(10) + P(5) + O(10)': C[0:5] + M +P[0:5] + O,\n",
    "    'C(5) + M(10) + P(5) + G(10) + O(10)': C[0:5] + M +P[0:5] + G + O,\n",
    "    'C(5) + M(5) + P(5))': C[0:5] + M +P[0:5],\n",
    "    'C(5) + M(5) + P(5) + G(5)': C[0:5] + M[0:5] +P[0:5] + G[0:5],\n",
    "    'C(5) + M(5) + P(5) + O(5)': C[0:5] + M[0:5] +P[0:5] + O[0:5],\n",
    "    'C(5) + M(5) + P(5) + G(5) + O(5)': C[0:5] + M[0:5] +P[0:5] + G[0:5] + O[0:5],\n",
    "    'C(5) + M(5) + P(5) + G(5) + O(5)': C[0:5] + M[0:5] +P[0:5] + G[0:5] + O[0:5],\n",
    "       }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_fin = {}\n",
    "fpr_fin = {}\n",
    "tpr_fin = {}\n",
    "for name_combi in list(temp.keys()):\n",
    "    var1 = temp[name_combi]\n",
    "    randomstate = 123\n",
    "    df = pd.concat([data,data_oral.dropna(how='all',axis = 1).fillna(0),data_gut.dropna(how='all',axis = 1).fillna(0)],1)[var1]\n",
    "    X_na = (df).copy()\n",
    "    meta = metadata.copy()\n",
    "    X=pd.DataFrame()\n",
    "    for i in meta.unique():\n",
    "        tempx=(X_na.reindex(meta[meta==i].index))\n",
    "        X=pd.concat([X,tempx.fillna(tempx.mean())])\n",
    "    y=meta.reindex(X.index)#.replace('Moderate','Severe').replace('Mild','None')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=randomstate)\n",
    "    def RF(it):\n",
    "        clf=RandomForestClassifier(n_estimators = it,bootstrap = True, oob_score = True, random_state = randomstate)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        return [it,metrics.accuracy_score(y_test, y_pred),clf.oob_score_]\n",
    "    select=list(map(RF,range(10,100)))\n",
    "    select = pd.DataFrame(select, columns=['var', 'accuracy', 'oob']).set_index('var')\n",
    "    selected = select.sort_values(['accuracy','oob']).drop_duplicates().index[-1]\n",
    "    clf=RandomForestClassifier(n_estimators = selected,bootstrap = True, oob_score = True, random_state = randomstate)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    roc_auc = dict()\n",
    "    roc_auc['Accuracy'] = metrics.accuracy_score(y_test, y_pred)\n",
    "    roc_auc['OOB Score'] = clf.oob_score_\n",
    "    \n",
    "    var1 = temp[name_combi]\n",
    "    randomstate = 123\n",
    "    df = pd.concat([data,data_oral.dropna(how='all',axis = 1).fillna(0),data_gut.dropna(how='all',axis = 1).fillna(0)],1)[var1]\n",
    "    X_na = (df).copy()\n",
    "    meta = metadata.copy()\n",
    "    X=pd.DataFrame()\n",
    "    for i in meta.unique():\n",
    "        tempx=(X_na.reindex(meta[meta==i].index))\n",
    "        X=pd.concat([X,tempx.fillna(tempx.mean())])\n",
    "    y=meta.reindex(X.index).replace('Moderate','Severe').replace('Mild','None')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=randomstate)\n",
    "    def RF(it):\n",
    "        clf=RandomForestClassifier(n_estimators = it,bootstrap = True, oob_score = True, random_state = randomstate)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        return [it,metrics.accuracy_score(y_test, y_pred),clf.oob_score_]\n",
    "    select=list(map(RF,range(10,100)))\n",
    "    select = pd.DataFrame(select, columns=['var', 'accuracy', 'oob']).set_index('var')\n",
    "    selected = select.sort_values(['accuracy','oob']).drop_duplicates().index[-1]\n",
    "    clf=RandomForestClassifier(n_estimators = selected,bootstrap = True, oob_score = True, random_state = randomstate)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds,pos_label='Severe')\n",
    "    roc_auc['auc'] = metrics.auc(fpr, tpr)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr, lw=2, color = 'green', label = 'AUC: %.3f' % (roc_auc['auc']))\n",
    "    plt.plot([-0.05, 1], [-0.05, 1], 'k--')\n",
    "    plt.title(name_combi)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.legend()\n",
    "    plt.savefig('../ResultsPaper/Figures/ROC/ROC_%s.pdf' % name_combi)\n",
    "    \n",
    "    X_na = v4.copy()\n",
    "    meta = X_na['Class']\n",
    "    del X_na['Class']\n",
    "    X_test=pd.DataFrame()\n",
    "    for i in meta.unique():\n",
    "        tempx=(X_na.reindex(meta[meta==i].index))\n",
    "        X_test=pd.concat([X_test,tempx.fillna(tempx.mean())])\n",
    "    y_test=meta.reindex(X_test.index).replace('Moderate','Severe').replace('Mild','None')\n",
    "    X_test = X_test.T.reindex(var1).T.fillna(0)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds,pos_label='Severe')\n",
    "    roc_auc['auc_v4'] = metrics.auc(fpr, tpr)\n",
    "    roc_auc['Accuracy_v4'] = metrics.accuracy_score(y_test, y_pred)\n",
    "    roc_auc['OOB Score_v4'] = clf.oob_score_\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr, lw=2, color = 'green', label = 'AUC: %.3f' % (roc_auc['auc_v4']))\n",
    "    plt.plot([-0.05, 1], [-0.05, 1], 'k--')\n",
    "    plt.title(name_combi)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.legend()\n",
    "    plt.savefig('../ResultsPaper/Figures/ROC/ROC_%s_v4.pdf' % name_combi)\n",
    "\n",
    "    auc_fin[name_combi] = roc_auc\n",
    "    tpr_fin[name_combi] = tpr\n",
    "    fpr_fin[name_combi] = fpr\n",
    "    \n",
    "fin_acc = pd.DataFrame.from_dict(auc_fin).T\n",
    "fin_acc.to_csv('../ResultsPaper/Figures/ROC/Accuracy.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.network_ori[k.network_ori['target'].str.contains('Liver')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N.xlsx',index_col=0, sheet_name='Dataset 1A').dropna(how='all',axis=1)\n",
    "data_clin = temp.iloc[0:,5:]\n",
    "metadata = temp['Liver Fat Class']\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 7N.xlsx')\n",
    "temp.sheet_names\n",
    "avail = temp.parse('Sample Availability',index_col=0)['Metabolomics']\n",
    "avail = avail[avail == 'YES']\n",
    "data_all = temp.parse('Raw Metabolomics Data',index_col=0)\n",
    "metadata = metadata.reindex(avail.index)\n",
    "data = data_all[avail.index]\n",
    "mapping_pw = data_all.iloc[0:,0:11]\n",
    "\n",
    "#remove metabolites with > 50% NA\n",
    "data_met = data[(data.isna().sum(1)/data.shape[1]) < 0.5].T\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 10N.xlsx')\n",
    "temp.sheet_names\n",
    "avail = temp.parse('Sample Availability',index_col=0)['Proteomics']\n",
    "avail = avail[avail == 'YES'] \n",
    "data_all = temp.parse('NPX Values',index_col=0)\n",
    "metadata = metadata.reindex(avail.index)\n",
    "data = data_all[avail.index]\n",
    "\n",
    "#remove proteins with > 50% NA\n",
    "data_prot = data[(data.isna().sum(1)/data.shape[1]) < 0.5].T\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 3N.xlsx')\n",
    "temp.sheet_names\n",
    "data_gut = temp.parse('Abundance_Gut',index_col=0)\n",
    "data_gut = data_gut[data_gut.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_gut.columns = [i.split('|')[-1][3:]+' (GUT)' for i in data_gut.columns]\n",
    "\n",
    "data_oral = temp.parse('Abundance_Oral',index_col=0)\n",
    "data_oral = data_oral[data_oral.index.str.contains('\\|s__')].dropna(how = 'all').T\n",
    "data_oral.columns = [i.split('|')[-1][3:]+' (ORAL)' for i in data_oral.columns]\n",
    "\n",
    "data = pd.concat([data_clin, data_met, data_prot, data_oral, data_gut],1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_prots = pd.DataFrame(pd.Series(data_prot.columns, index = data_prot.columns, name = \"Symbol\"))\n",
    "nodes_prots['Location'] = 'PROTEIN'\n",
    "nodes_clin = pd.DataFrame(pd.Series(data_clin.columns, index = data_clin.columns, name = \"Symbol\"))\n",
    "nodes_clin['Location'] = 'CLINICAL'\n",
    "nodes_mets = pd.DataFrame(pd.Series(data_met.columns, index = data_met.columns, name = \"Symbol\"))\n",
    "nodes_mets['Location'] = 'METABOLITE'\n",
    "nodes_sal = pd.DataFrame(pd.Series([i.split(' ')[0] for i in data_oral.columns], index = data_oral.columns, name = \"Symbol\"))\n",
    "nodes_sal['Location'] = 'ORAL MICROBIOME'\n",
    "nodes_fec = pd.DataFrame(pd.Series([i.split(' ')[0] for i in data_gut.columns], index = data_gut.columns, name = \"Symbol\"))\n",
    "nodes_fec['Location'] = 'GUT MICROBIOME'\n",
    "\n",
    "nodes = pd.concat([nodes_mets,nodes_prots,nodes_clin, nodes_sal, nodes_fec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('StartingNet')\n",
    "\n",
    "k=Network_Analysis(raw_data=data,nodes=nodes,respath='../ResultsPaper/DS/')\n",
    "k.save_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 16N.xlsx')\n",
    "edges = temp.parse('Edges')\n",
    "nodes = temp.parse('Nodes',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 15N.xlsx',index_col=0,sheet_name='C(5)+M(5)+P(5)+G(5)+O(5)')\n",
    "selected_analytes = temp[temp['P value (Severe vs None)']<0.05].sort_values('Location').index.tolist() + ['Liver fat (%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_analytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_temp = edges[edges['pvalue']<0.05]\n",
    "edges_temp = edges_temp[edges_temp['source'].isin(selected_analytes) | edges_temp['target'].isin(selected_analytes)]\n",
    "nodes_temp = nodes.reindex(set(edges_temp['source'].tolist()+edges_temp['target'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_clin = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 1N_1D.xlsx',index_col=0)\n",
    "stats_clin = stats_clin[stats_clin.columns[stats_clin.columns.str.contains(' vs ')]]\n",
    "stats_clin['Location'] = 'CLINICAL'\n",
    "\n",
    "stats_met = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 8N.xlsx',index_col=0)\n",
    "stats_met = stats_met[stats_met.columns[stats_met.columns.str.contains(' vs ')]]#.iloc[0:,0:-3]\n",
    "stats_met['Location'] = 'METABOLITE'\n",
    "\n",
    "stats_prot = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 11N.xlsx',index_col=0)\n",
    "stats_prot = stats_prot[stats_prot.columns[stats_prot.columns.str.contains(' vs ')]]\n",
    "stats_prot['Location'] = 'PROTEIN'\n",
    "\n",
    "\n",
    "stats_gut = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 4N.xlsx',index_col=0, sheet_name='Gut')\n",
    "stats_gut = stats_gut[stats_gut.columns[stats_gut.columns.str.contains(' vs ')]]\n",
    "stats_gut.index = stats_gut.index + ' (GUT)'\n",
    "stats_gut['Location'] = 'GUT'\n",
    "\n",
    "\n",
    "stats_oral = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 4N.xlsx',index_col=0, sheet_name='Oral')\n",
    "stats_oral = stats_oral[stats_oral.columns[stats_oral.columns.str.contains(' vs ')]]\n",
    "stats_oral.index = stats_oral.index + ' (ORAL)'\n",
    "stats_oral['Location'] = 'ORAL'\n",
    "\n",
    "stats_all = pd.concat([stats_clin, stats_met, stats_prot,stats_oral,stats_gut])\n",
    "\n",
    "temp=pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 7N.xlsx')\n",
    "mapping_pw = temp.parse('Raw Metabolomics Data',index_col=0).iloc[0:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_temp = pd.concat([nodes_temp,stats_all,mapping_pw],1)\n",
    "nodes_temp = nodes_temp[~nodes_temp['Symbol'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_sig=(nodes_temp[nodes_temp.columns[nodes_temp.columns.str.contains('P va')]] < 0.05).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_temp['dir'] = ['down' if i>0 else np.nan for i in temp_sig]\n",
    "nodes_temp['main'] = ['yes' if i in selected_analytes else 'no' for i in nodes_temp.index]\n",
    "edges_temp['Dir'] = ['Down' if i<0 else 'Up' for i in edges_temp['correlation']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_temp.to_csv('../ResultsPaper/NET/edges.txt',sep='\\t',index=False)\n",
    "nodes_temp.to_csv('../ResultsPaper/NET/nodes.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_temp = edges[edges['padj']<0.05]\n",
    "edges_temp['category'] = 1\n",
    "nodes_temp = nodes.reindex(set(edges_temp['source'].tolist()+edges_temp['target'].tolist()))\n",
    "nodes_temp = nodes_temp[nodes_temp['cluster'].notna()]\n",
    "nodes_temp.loc[nodes_temp['cluster'] > 3,'cluster'] = 3\n",
    "nodes_temp['cluster'] = nodes_temp['cluster'].astype(int)\n",
    "\n",
    "\n",
    "edges_temp['cl_s'] = nodes_temp.reindex(edges_temp.source)['cluster'].astype(int).tolist()\n",
    "edges_temp['cl_t'] = nodes_temp.reindex(edges_temp.target)['cluster'].astype(int).tolist()\n",
    "edges_temp['weight1'] = np.sign(edges_temp['correlation'])\n",
    "edges_cl = edges_temp[edges_temp['cl_t'] != edges_temp['cl_s']]\n",
    "edges_cl=edges_cl.groupby(['cl_s','cl_t']).sum().reset_index()[['cl_s','cl_t','category','weight1']]\n",
    "edges_cl.columns = ['source', 'target', 'weight', 'dir']\n",
    "edges_cl['name'] = ['%d - %d' % (sorted([i,j])[0],sorted([i,j])[1]) for i,j in zip(edges_cl['source'],edges_cl['target'])]\n",
    "edges_cl = edges_cl.groupby('name').sum().reset_index()\n",
    "edges_cl['source'] = [int(i.split(' - ')[0]) for i in edges_cl['name']]\n",
    "edges_cl['target'] = [int(i.split(' - ')[1]) for i in edges_cl['name']]\n",
    "edges_cl['dir'] = np.sign(edges_cl['dir'])\n",
    "# edges_cl = edges_cl[edges_cl['weight'] > edges_cl['weight'].quantile(.25)][['source','target','weight','dir']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_cl.to_csv('../ResultsPaper/NET/edges_cluster.txt',sep='\\t',index=False)\n",
    "nodes_cl = pd.concat([nodes_temp.groupby(['cluster'])['Symbol'].count(),nodes_temp.groupby(['cluster','Location'])['Symbol'].count().reset_index().pivot_table(columns = 'Location', index = 'cluster', values = 'Symbol')],1)\n",
    "nodes_cl.to_csv('../ResultsPaper/NET/nodes_cluster.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6A - C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('../ResultsPaper/Figures/ROC/Accuracy.txt',sep = '\\t')\n",
    "plt.figure(figsize = (20,10))\n",
    "g = sns.barplot(data = temp, x = 'Unnamed: 0', y = 'Accuracy',color = 'gray')\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right', fontweight = 'bold')\n",
    "plt.savefig('../ResultsPaper/Figures/Figure 6A.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = pd.read_excel('../ResultsPaper/DS/Supplementary Dataset 15N.xlsx',index_col = 0, sheet_name='C(5)+M(5)+P(5)+G(5)+O(5)')\n",
    "plt.figure(figsize = (10,7.5))\n",
    "temp1[i] = ['[*] ' + i if temp1.loc[i]['P value (Severe vs None)'] < 0.05 else i for i in temp1.index]\n",
    "sns.barplot(data = temp1, y = i, x = 'Importance',color = 'gray')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.savefig('../ResultsPaper/Figures/Figure 6F.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure S6 + S7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.ExcelFile('../ResultsPaper/DS/Supplementary Dataset 15N.xlsx')\n",
    "# temp.sheet_names\n",
    "for i in temp.sheet_names[0:5]:\n",
    "    plt.figure(figsize = (10,7.5))\n",
    "    if i != 'Combinations':\n",
    "        temp1 = temp.parse(i,index_col = 0).iloc[0:20,0:]\n",
    "    else:\n",
    "        temp1 = temp.parse(i,index_col = 0).iloc[0:20,0:]\n",
    "    temp1[i] = ['[*] ' + i if temp1.loc[i]['P value (Severe vs None)'] < 0.05 else i for i in temp1.index]\n",
    "    sns.barplot(data = temp1, y = i, x = 'Importance',color = 'gray')\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.savefig('../ResultsPaper/Figures/RF_%s.pdf' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
